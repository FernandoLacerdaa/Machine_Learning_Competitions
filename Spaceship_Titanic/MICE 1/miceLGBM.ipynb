{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "fa7491e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score,f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "1aea0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "bf768d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "c4e178b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "d38b0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "53593954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "3a7846e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d3cef36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "1b3ee13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "c07bc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"PassengerId\", \"Name\"],inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "753b941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13208\\2437142087.py:1: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  df[[\"c1\", \"c2\", \"c3\"]] = df[\"Cabin\"].str.split(\"/\", 2, expand=True)\n"
     ]
    }
   ],
   "source": [
    "df[[\"c1\", \"c2\", \"c3\"]] = df[\"Cabin\"].str.split(\"/\", 2, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "3f575d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Cabin  Destination   Age    VIP  RoomService  \\\n",
       "0     Europa     False  B/0/P  TRAPPIST-1e  39.0  False          0.0   \n",
       "1      Earth     False  F/0/S  TRAPPIST-1e  24.0  False        109.0   \n",
       "2     Europa     False  A/0/S  TRAPPIST-1e  58.0   True         43.0   \n",
       "3     Europa     False  A/0/S  TRAPPIST-1e  33.0  False          0.0   \n",
       "4      Earth     False  F/1/S  TRAPPIST-1e  16.0  False        303.0   \n",
       "\n",
       "   FoodCourt  ShoppingMall     Spa  VRDeck  Transported c1 c2 c3  \n",
       "0        0.0           0.0     0.0     0.0        False  B  0  P  \n",
       "1        9.0          25.0   549.0    44.0         True  F  0  S  \n",
       "2     3576.0           0.0  6715.0    49.0        False  A  0  S  \n",
       "3     1283.0         371.0  3329.0   193.0        False  A  0  S  \n",
       "4       70.0         151.0   565.0     2.0         True  F  1  S  "
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "050e5f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"c3\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "8c8ae508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1817"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"c2\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "627b5bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"c1\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c59f919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"c2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "ba4f9059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Cabin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "45b97d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Transported\"] = df[\"Transported\"] .map({True:1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "64daa3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_id_cabin = df.pop(\"Transported\")\n",
    "df.insert(len(df.columns), 'Transported', pop_id_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "b19f8ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>c1</th>\n",
       "      <th>c3</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "0     Europa     False  TRAPPIST-1e  39.0  False          0.0        0.0   \n",
       "1      Earth     False  TRAPPIST-1e  24.0  False        109.0        9.0   \n",
       "2     Europa     False  TRAPPIST-1e  58.0   True         43.0     3576.0   \n",
       "3     Europa     False  TRAPPIST-1e  33.0  False          0.0     1283.0   \n",
       "4      Earth     False  TRAPPIST-1e  16.0  False        303.0       70.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck c1 c3  Transported  \n",
       "0           0.0     0.0     0.0  B  P            0  \n",
       "1          25.0   549.0    44.0  F  S            1  \n",
       "2           0.0  6715.0    49.0  A  S            0  \n",
       "3         371.0  3329.0   193.0  A  S            0  \n",
       "4         151.0   565.0     2.0  F  S            1  "
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "ffd35b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:len(df.columns)-1]\n",
    "y = df[\"Transported\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "f4619280",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "ab3507ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = np.array([coluna for coluna in X_train.columns if X_train[coluna].dtypes.name==\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "04a3b214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'c1', 'c3'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "0259f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.array([coluna for coluna in X_train.columns if coluna not in cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "5c0cdcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "f7d788ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TargetEncoder(cols=[&#x27;HomePlanet&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;VIP&#x27;, &#x27;c1&#x27;,\n",
       "                    &#x27;c3&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;, smoothing=0.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" checked><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder(cols=[&#x27;HomePlanet&#x27;, &#x27;CryoSleep&#x27;, &#x27;Destination&#x27;, &#x27;VIP&#x27;, &#x27;c1&#x27;,\n",
       "                    &#x27;c3&#x27;],\n",
       "              handle_missing=&#x27;return_nan&#x27;, smoothing=0.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TargetEncoder(cols=['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'c1',\n",
       "                    'c3'],\n",
       "              handle_missing='return_nan', smoothing=0.0)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TargetEncoder(\n",
    "    cols=cat,\n",
    "    smoothing=0.0,           # you can tweak this\n",
    "    handle_unknown='value',  # how to treat unseen categories\n",
    "    handle_missing='return_nan'  # <-- preserves NaNs instead of filling\n",
    ")\n",
    "\n",
    "# 3. Fit on your training data\n",
    "#    Only fit on the categorical columns and the target\n",
    "te.fit(X_train[cat], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "118e8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = te.transform(X_train[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "1ae094f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = te.transform(X_test[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "747ec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([\n",
    "    X_test.drop(columns=cat).reset_index(drop=True),\n",
    "    X_test_2.reset_index(drop=True)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "920e2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>VIP</th>\n",
       "      <th>c1</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>0.527650</td>\n",
       "      <td>0.330327</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.430128</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.422499</td>\n",
       "      <td>0.330327</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422499</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422499</td>\n",
       "      <td>0.330327</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>0.449083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658354</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.433908</td>\n",
       "      <td>0.449083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  RoomService  FoodCourt  ShoppingMall  Spa  VRDeck  HomePlanet  \\\n",
       "0  19.0        417.0      349.0         634.0  3.0  1057.0    0.527650   \n",
       "1  18.0          4.0      904.0           0.0  0.0     1.0    0.422499   \n",
       "2  41.0          0.0        0.0           0.0  0.0     0.0    0.422499   \n",
       "3  35.0          0.0      338.0         436.0  NaN     0.0    0.422499   \n",
       "4  43.0          0.0        0.0           0.0  0.0     0.0    0.658354   \n",
       "\n",
       "   CryoSleep  Destination       VIP        c1        c3  \n",
       "0   0.330327     0.474243  0.506838  0.430128  0.557219  \n",
       "1   0.330327     0.474243  0.506838  0.518461  0.557219  \n",
       "2   0.818828     0.474243  0.506838  0.518461  0.557219  \n",
       "3   0.330327     0.474243  0.506838  0.518461  0.449083  \n",
       "4   0.818828     0.474243  0.506838  0.433908  0.449083  "
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "286e2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([\n",
    "    X_train.drop(columns=cat).reset_index(drop=True),\n",
    "    X_train_enc.reset_index(drop=True)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "4e701c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>VIP</th>\n",
       "      <th>c1</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527650</td>\n",
       "      <td>0.330327</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.430128</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658354</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.601913</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.726510</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658354</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.726510</td>\n",
       "      <td>0.557219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422499</td>\n",
       "      <td>0.818828</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>0.449083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.422499</td>\n",
       "      <td>0.330327</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>0.506838</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>0.449083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  RoomService  FoodCourt  ShoppingMall    Spa  VRDeck  HomePlanet  \\\n",
       "0  27.0        441.0        0.0         397.0  471.0     0.0    0.527650   \n",
       "1  45.0          0.0        0.0           0.0    0.0     0.0    0.658354   \n",
       "2  50.0          0.0        0.0           0.0    0.0     0.0    0.658354   \n",
       "3   1.0          0.0        0.0           0.0    0.0     0.0    0.422499   \n",
       "4  42.0          0.0       29.0         317.0  434.0    45.0    0.422499   \n",
       "\n",
       "   CryoSleep  Destination       VIP        c1        c3  \n",
       "0   0.330327     0.474243  0.506838  0.430128  0.557219  \n",
       "1   0.818828     0.601913  0.506838  0.726510  0.557219  \n",
       "2   0.818828     0.474243  0.506838  0.726510  0.557219  \n",
       "3   0.818828     0.474243  0.506838  0.518461  0.449083  \n",
       "4   0.330327     0.474243  0.506838  0.518461  0.449083  "
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "b2b57ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "f3062a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "25d63a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(random_state=100, estimator=cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "be7485c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1130\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1131\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1381\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1171\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1172\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1347\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1446\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1452\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1290\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1534\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1583\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1625\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1430\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1637\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1575\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1583\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1589\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1637\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1632\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1435\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1644\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1436\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1438\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1581\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1591\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1597\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1628\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1435\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1643\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1575\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1585\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1591\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1434\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1637\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1631\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1430\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1640\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1430\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1430\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1573\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1583\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1589\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1424\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1632\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1637\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1633\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1434\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1643\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1578\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1592\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1428\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1635\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1632\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1430\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1641\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1577\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1587\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1593\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1434\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1633\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1639\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1633\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1437\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1644\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1579\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1589\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1595\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1435\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1641\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1633\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1431\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1438\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1645\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1435\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1435\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1580\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1590\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1596\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1432\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1638\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1435\n",
      "[LightGBM] [Info] Number of data points in the train set: 6399, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 222.609939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6394, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 315.067407\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1644\n",
      "[LightGBM] [Info] Number of data points in the train set: 6387, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.504306\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1433\n",
      "[LightGBM] [Info] Number of data points in the train set: 6386, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 460.503132\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1436\n",
      "[LightGBM] [Info] Number of data points in the train set: 6384, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 307.743734\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1577\n",
      "[LightGBM] [Info] Number of data points in the train set: 6377, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 28.849773\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1586\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503771\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1592\n",
      "[LightGBM] [Info] Number of data points in the train set: 6369, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503533\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1429\n",
      "[LightGBM] [Info] Number of data points in the train set: 6365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 175.153496\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1634\n",
      "[LightGBM] [Info] Number of data points in the train set: 6364, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503457\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1639\n",
      "[LightGBM] [Info] Number of data points in the train set: 6360, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503931\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1636\n",
      "[LightGBM] [Info] Number of data points in the train set: 6354, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.503462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Anaconda\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:796: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IterativeImputer(estimator=LGBMRegressor(), random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(estimator=LGBMRegressor(), random_state=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "IterativeImputer(estimator=LGBMRegressor(), random_state=100)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "a6783e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed  = imputer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "d74cf9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed = pd.DataFrame(\n",
    "    imputed,\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "a1b60805",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "0cb77623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name     results.mean     results.std\n",
      "LGBMtun (0.8079466215293636, 0.0033461882689026856)\n",
      "xgb (0.8053378470636428, 0.0032189126408912836)\n",
      "cat2 (0.8067195099557887, 0.005014223035810745)\n",
      "cat (0.8082536054127096, 0.003017556197715297)\n",
      "LGBM (0.8076389313947521, 0.0058572543000513086)\n",
      "xgb50,3 (0.8045716821492638, 0.003520359312472062)\n",
      "LGBM2 (0.8041110886157004, 0.0072676900895788)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append((\"LGBMtun\",LGBMClassifier(learning_rate=0.05, num_leaves=20, max_depth=14,verbose=-1)))\n",
    "models.append((\"xgb\",xgb.XGBClassifier()))\n",
    "models.append((\"cat2\",CatBoostClassifier(bagging_temperature=0.2938751257578318,border_count=170,depth=4,\n",
    "                                        iterations=97,l2_leaf_reg=6,learning_rate=0.37852785960662555,\n",
    "                                        random_strength=0.6918358593649996,scale_pos_weight=0.7881952275877159,\n",
    "                                        verbose=False)))\n",
    "models.append((\"cat\",CatBoostClassifier(verbose=False)))\n",
    "models.append((\"LGBM\",LGBMClassifier(learning_rate=0.05, max_depth=20, n_estimators=200,verbose=-1)))\n",
    "models.append((\"xgb50,3\",xgb.XGBClassifier(n_estimators=50, learning_rate=0.3)))\n",
    "models.append((\"LGBM2\",LGBMClassifier(learning_rate=0.2,verbose=-1)))\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for  name, model in models:\n",
    "\tskf = StratifiedKFold(n_splits = 5, random_state=None)\n",
    "\tcv_results = cross_val_score(model,X_train,y_train,cv=skf, scoring=\"accuracy\")\n",
    "\tresults[name]= (cv_results.mean(), cv_results.std())\n",
    "\n",
    "print(\"name     results.mean     results.std\")\n",
    "\n",
    "for key,value in results.items():\n",
    "\tprint(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "460838b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\"n_estimators\":[100,200,300], \n",
    "               \"learning_rate\":[0.01,0.05,0.1,0.3],\n",
    "               \"max_depth\":[20,50,80,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "887dfb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmc = LGBMClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "3c5e9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV (estimator = lgbmc,\n",
    "                            param_grid = lgbm_params,\n",
    "                            n_jobs=-1,\n",
    "                            cv = 5,\n",
    "                            scoring=\"accuracy\",\n",
    "                           error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "c53b33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 3286, number of negative: 3233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1696\n",
      "[LightGBM] [Info] Number of data points in the train set: 6519, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504065 -> initscore=0.016261\n",
      "[LightGBM] [Info] Start training from score 0.016261\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "final_model = lgbmc.set_params(**grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "4774082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 3286, number of negative: 3233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1696\n",
      "[LightGBM] [Info] Number of data points in the train set: 6519, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504065 -> initscore=0.016261\n",
      "[LightGBM] [Info] Start training from score 0.016261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=50, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" checked><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=50, n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, max_depth=50, n_estimators=300)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "d1fb95b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "7aee2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed = pd.DataFrame(\n",
    "    imputed_test,\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "d5517dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "7452ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "6ad948b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7948482060717571"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "2c06aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_pred, y_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "recall = precision_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test)\n",
    "\n",
    "score = []\n",
    "score.append((\"precision\", precision))\n",
    "score.append((\"accuracy\",accuracy))\n",
    "score.append((\"recall\",recall))\n",
    "score.append((\"f1\",f1))\n",
    "\n",
    "score= pd.DataFrame(score)\n",
    "score.rename(columns={0: \"Metric\", 1:\"Result\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "74d10fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.804945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.794848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.804945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.797641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric    Result\n",
       "0  precision  0.804945\n",
       "1   accuracy  0.794848\n",
       "2     recall  0.804945\n",
       "3         f1  0.797641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "433d2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "testecsv = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "c69e8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "testecsv[[\"c1\",\"c2\",\"c3\"]] = testecsv[\"Cabin\"].str.split(\"/\", n=2, expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "60f114d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = testecsv.drop(columns=[\"PassengerId\",\"Cabin\",\"Name\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "25444654",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste.drop(columns=[\"c2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "20445e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>c1</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "0      Earth      True  TRAPPIST-1e  27.0  False          0.0        0.0   \n",
       "1      Earth     False  TRAPPIST-1e  19.0  False          0.0        9.0   \n",
       "2     Europa      True  55 Cancri e  31.0  False          0.0        0.0   \n",
       "3     Europa     False  TRAPPIST-1e  38.0  False          0.0     6652.0   \n",
       "4      Earth     False  TRAPPIST-1e  20.0  False         10.0        0.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck c1 c3  \n",
       "0           0.0     0.0     0.0  G  S  \n",
       "1           0.0  2823.0     0.0  F  S  \n",
       "2           0.0     0.0     0.0  C  S  \n",
       "3           0.0   181.0   585.0  C  S  \n",
       "4         635.0     0.0     0.0  F  S  "
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "02b64f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste_enc = te.transform(X_teste[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "ccad2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = pd.concat([\n",
    "    X_teste.drop(columns=cat).reset_index(drop=True),\n",
    "    X_teste_enc.reset_index(drop=True)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "91e25dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputedf = imputer.transform(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "4dbf34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = pd.DataFrame(\n",
    "    imputedf,\n",
    "    columns=X_teste.columns,\n",
    "    index=X_teste.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "5d64e150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5623    0\n",
       "5253    1\n",
       "478     1\n",
       "1352    1\n",
       "5344    1\n",
       "       ..\n",
       "5734    1\n",
       "5191    0\n",
       "5390    0\n",
       "860     0\n",
       "7270    0\n",
       "Name: Transported, Length: 6519, dtype: int64"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "e0df44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([X_train, X_test], axis=0).reset_index(drop=True)\n",
    "y_all = pd.concat([y_train, y_test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "fcaebf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1795\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=50, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" checked><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=50, n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, max_depth=50, n_estimators=300)"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_all, y_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "d37d110b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "y_predz = final_model.predict(X_teste)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "9d73f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "subimisspace = pd.Series(index = testecsv[\"PassengerId\"].values, data = y_predz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "ebc502b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subimisspace = subimisspace.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "178a160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subimisspace = pd.DataFrame(subimisspace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "c6bedde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subimisspace[0]=subimisspace[0].map({1:\"True\", 0:\"False\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "3dbd2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subimisspace.rename(columns = {\"index\":\"PassengerId\", 0:\"Transported\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "c9e76368",
   "metadata": {},
   "outputs": [],
   "source": [
    "subimisspace.to_csv(\"lajoy.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
